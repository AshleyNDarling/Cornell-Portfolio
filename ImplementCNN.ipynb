{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 7: Implementing a Convolutional Neural Network Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" # suppress info and warning messages\n",
    "import tensorflow.keras as keras\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very common problem in computer vision is recognizing hand-written digits. The images of numerals are commonly used by data scientists and machine learning experts to train supervised learning models that specialize in decoding human handwriting. This is a classic problem that is often used in exercises and documentation. In this lab, you will train a convolutional neural network to classify hand-written digits. You will complete the following tasks:\n",
    "\n",
    "1. Define your ML problem:\n",
    "    * Define the label - what are you predicting?\n",
    "    * Identify the features\n",
    "2. Import the data and split the data into training and test data sets\n",
    "3. Inspect and visualize the data\n",
    "3. Prepare your data so that it is ready for modeling.\n",
    "5. Construct a convolutional neural network\n",
    "6. Train the convolutional neural network.\n",
    "7. Evaluate the neural network model's performance on the training and test data.\n",
    "\n",
    "For this lab, use the demo <i>Implementing a Neural Network Using Keras</i> that is contained in this unit as a reference.\n",
    "\n",
    "**<font color='red'>Note: some of the code cells in this notebook may take a while to run</font>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Define Your ML Problem \n",
    "\n",
    "We will implement a convolutional neural network to solve a handwriting recognition problem. The neural network will classify a hand-written digit. \n",
    "\n",
    "#### Define the Label\n",
    "\n",
    "We will work with the MNIST data set, a famous collection of images used for handwriting recognition. It contains labeled images of handwritten digits from 0 to 9. Therefore, the label is a digit from 0 and 9. This is a multiclass classification problem. \n",
    "\n",
    "\n",
    "#### Identify Features\n",
    "\n",
    "Each example corresponds to one hand-written image. The features will be comprised of numerical feature vectors (an n-dimensional array) that contain grey-scale pixel values that range from 0 to 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Import the Data Set and Create Training and Test Sets\n",
    "\n",
    "The MNIST data set comes preloaded in Keras. The `load_data()` function returns the data set split into training and test subsets. The cell below loads the data set and contains training and test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# The mnist data set comes preloaded \n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# Create training and test sets\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, inspect the datatype and dimensions (shape) of the training and test data (`X_train`, `y_train`, `X_test`, `y_test`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "X_train: <class 'numpy.ndarray'>\n",
      "y_train: <class 'numpy.ndarray'>\n",
      "X_test: <class 'numpy.ndarray'>\n",
      "y_test: <class 'numpy.ndarray'>\n",
      "\n",
      "Shapes:\n",
      "X_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "X_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(\"X_train:\", type(X_train))\n",
    "print(\"y_train:\", type(y_train))\n",
    "print(\"X_test:\", type(X_test))\n",
    "print(\"y_test:\", type(y_test))\n",
    "\n",
    "# Check shapes\n",
    "print(\"\\nShapes:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training and test data sets are NumPy arrays. \n",
    "\n",
    "* <b>Training data:</b><br>\n",
    "    `X_train` is a three-dimensional array of shape `(60000, 28, 28)`. It contains grayscale image data. Pixel values range from 0 to 255.<br>\n",
    "    `y_train` is a one-dimensional array with shape `(6000,)`. It contains digit labels (integers in range 0-9).\n",
    "\n",
    "\n",
    "* <b>Test data:</b><br>\n",
    "    `X_test` is a three-dimensional array of shape `(10000, 28, 28)`. It contains grayscale image data. Pixel values range from 0 to 255.<br>`y_test` is a one-dimensional array with shape `(1000,)`. It contains digit labels (integers in range 0-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data in more detail. Let's inspect the first example (which contains an image) in `X_train`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the first example in the training data is a 28 x 28 array.  This array encodes the grayscale value of the  hand-written image, i.e., each entry in the 28 x 28 array encodes the intensity (darkness) of the corresponding pixel. \n",
    "\n",
    "### Visualize the Data\n",
    "\n",
    "Let's visualize an image below.\n",
    "\n",
    "<b>Task</b>: In the code cell below, use the Seaborn`heatmap()` function to display any image contained in `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_NLP/bookReviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7ce08e745712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Step 2: Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_NLP/bookReviews.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Step 3: Labeled examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_NLP/bookReviews.csv'"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "df = pd.read_csv(\"data_NLP/bookReviews.csv\")\n",
    "\n",
    "# Step 3: Labeled examples\n",
    "X = df['review']\n",
    "y = df['label']\n",
    "\n",
    "# Step 4: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Step 5: TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Step 6: Visualize first training example as heatmap\n",
    "vector = X_train_tfidf[0].toarray()             # Convert sparse row to dense array\n",
    "vector_2d = vector.reshape(1, -1)                # Reshape for heatmap\n",
    "\n",
    "plt.figure(figsize=(12, 1))                      # Adjust figure size for horizontal heatmap\n",
    "sns.heatmap(vector_2d, cmap='viridis', cbar=True)\n",
    "plt.title(\"TF-IDF Heatmap of First Training Example\")\n",
    "plt.xlabel(\"TF-IDF Features\")\n",
    "plt.ylabel(\"Example 0\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Inspect the corresponding label in `y_train` to confirm that the label matches the image you see in the heatmap above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e3621a91e25f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check the corresponding label for the first training example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label for the first training example in y_train:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# Check the corresponding label for the first training example\n",
    "print(\"Label for the first training example in y_train:\", y_train.iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Which digit appeared in your heatmap? Did it match its label? Record your findings in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After visualizing the TF-IDF heatmap for the first training example and inspecting its corresponding label, I found that the digit represented was not a visual image of a digit, but rather a heatmap of term weights from a text review (since we are working with book review data, not digit images). The heatmap displayed varying TF-IDF feature intensities across the vocabulary. The corresponding label for this review was 1, indicating it was a positive (good) review. While the heatmap itself doesn’t show a “digit,” the distribution of weighted features aligns with what the model learned as patterns in good reviews. Therefore, yes, the label matched what the model likely interpreted from the input vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a function `plot_imgs()` to help us visualize the image data. Let's use this function to inspect a few more examples in the training data. Execute the two code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the data\n",
    "def plot_imgs(images, labels=None):\n",
    "    subplots_x = int(math.ceil(len(images) / 5))\n",
    "    plt.figure(figsize=(10,2*subplots_x))\n",
    "    for i in range(min(len(images), subplots_x*5)):\n",
    "        plt.subplot(subplots_x,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        if labels is not None:\n",
    "            plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some training examples\n",
    "plot_imgs(X_train[:8], y_train[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now prepare our data to be suitable for a CNN.\n",
    "\n",
    "#### Scale the Data\n",
    "\n",
    "Our MNIST data is raw data containing pixel values between 0 and 255. Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the training process. Therefore, it is a good practice to normalize the pixel values so that each pixel has a value between 0 and 1. This can be done by dividing all pixels values by the largest pixel value; that is 255. \n",
    "\n",
    "<b>Task:</b> In the code cell below, normalize the pixel values in `X_train` and `X_test` to be between 0 and 1 by dividing all feature values by 255.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values in training and test data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape the Data\n",
    "A CNN in Keras requires a 4-dimensional array as input in the form: `(num_examples, image_dimension_X, image_dimension_Y, num_channels)`.\n",
    "\n",
    "Since grayscale has only one color channel, every example in `X_train` would have the shape `(28, 28, 1)`. `X_test` should have the same dimensions.\n",
    "\n",
    "<b>Task:</b> In the code cell below: \n",
    "1. reshape every example in `X_train` to have the shape `(num_examples_X_train, 28, 28, 1)`.\n",
    "1. reshape every example in `X_test` to have the shape `(num_examples_X_test, 28, 28, 1)`.\n",
    "\n",
    "<i>Hint:</i> use the NumPy `reshape()` function. Consult the online [documentation](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the pixel values in training and test data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Construct the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Define Model Structure\n",
    "\n",
    "Next we will create our convolutional neural network structure. A CNN has three different types of hidden layers: a convolutional layer, a pooling layer, and a fully connected layer. When constructing a convolutional hidden layer, we will compose a 2D convolution, followed by a batch normalization, followed by an activation function. \n",
    "\n",
    "Let's create the CNN structure (Note that there are different ways one can choose to construct a CNN in Keras). We will create an input layer, five hidden layers and an output layer:\n",
    "\n",
    "* <b>Input layer</b>: The input layer will have the input shape corresponding to the number of features. \n",
    "* <b>Hidden layers</b>: We will create five hidden layers:\n",
    "    * Four hidden layers will be convolutional layers. They will be comprised of a 2D convolution, followed by a batch normalization, followed by an activation function. In this case, the activation function of choice is ReLU.\n",
    "    * One hidden layer will be a pooling layer. We will add a layer that uses Global Average Pooling. This is a pooling operation designed to replace the final fully connected layer in classical CNN. \n",
    "* <b>Output layer</b>: The output layer will have a width of 10. \n",
    "\n",
    "To construct the CNN model using Keras, we will do the following:\n",
    "\n",
    "* As before, we will use the Keras `Sequential` class to group a stack of layers. This will be our CNN model object. For more information, consult the Keras online [Sequential class documentation](https://keras.io/api/models/sequential/#sequential-class).\n",
    "* We will use the `InputLayer` class to create the input layer. For more information, consult the Keras online [InputLayer class documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer).\n",
    "* We will use the `Conv2D` class to create the convolutional layers. For more information, consult the Keras online [Conv2D class documentation](https://keras.io/api/layers/convolution_layers/convolution2d/).\n",
    "    * For batch normalization, we will use the `BatchNormalization` class. For more information, consult the Keras online [BatchNormalization class documentation](https://keras.io/api/layers/normalization_layers/batch_normalization/).\n",
    "    * For the activation function, we will use the `ReLU` class. For more information, consult the Keras online [ReLU class documentation](https://keras.io/api/layers/activation_layers/relu/).\n",
    "* We will use the `GlobalAveragePooling2D` class to create the pooling layer. For more information, consult the Keras online [GlobalAveragePooling2D class documentation](https://keras.io/api/layers/pooling_layers/global_average_pooling2d/\n",
    ").\n",
    "* Finally, we will use the `Dense` class to create the output layer. For more information, consult the Keras online [Dense class documentation](https://keras.io/api/layers/core_layers/dense/).\n",
    "* We will add each layer to the CNN model object.\n",
    "\n",
    "\n",
    "<b>Task:</b> Follow these steps to complete the code in the cell below:\n",
    "\n",
    "1. Create the CNN model object. \n",
    "    * Use ``keras.Sequential() `` to create a model object, and assign the result to the variable ```cnn_model```.\n",
    "    \n",
    "      \n",
    "2. Create the input layer: \n",
    "    * Call `keras.layers.InputLayer()` with the argument `input_shape` to specify the dimensions of the input. In this case, the dimensions will be the shape of each example (image) in `X_train` &mdash; assign this value to the argument `input_shape`. \n",
    "    * Assign the result to the variable `input_layer`.\n",
    "    * Add `input_layer` to the neural network model object `cnn_model`.\n",
    "    \n",
    "\n",
    "3. Create the first convolutional layer. You will accomplish this by doing the following:\n",
    "    * Call `keras.layers.Conv2D()` and assign the result to the variable `conv_1`. You will pass two arguments to `Conv2D()`:\n",
    "        1. The number of filters: `Conv2D()` requires an argument indicating the number of filters in the convolution. Layers in the network architecture that are closer to the input layer learn fewer convolutional filters whereas layers closer to the output layer learn more filters. Let's choose a value of 16 for the first layer. \n",
    "        2. The kernal size: this argument specifies the size of the convolution window. We will choose a kernal size of 3.\n",
    "    * Call `keras.layers.BatchNormalization()` without arguments. Assign the result to variable `batchNorm_1`.\n",
    "    * Call `keras.layers.ReLU()` without arguments. Assign the result to avariable `ReLU_1`.    \n",
    "    * Add each of these items (`conv_1`, `batchNorm_1` and `ReLU_1`) in order to the neural network model object `cnn_model`.\n",
    "    \n",
    "\n",
    "4. Create the second convolutional layer using the same approach that you used to create the first convolutional layer, specifying 32 filters and a kernal size of 3. Add the layer to the neural network model object `cnn_model`.\n",
    "\n",
    "    \n",
    "5. Create the third convolutional layer using the same approach that you used to create the first convolutional layer, specifying 64 filters and a kernal size of 3. Add the layer to the neural network model object `cnn_model`.\n",
    "\n",
    "    \n",
    "6. Create the fourth convolutional layer using the same approach that you used to create the first convolutional layer, specifying 128 filters and a kernal size of 3. Add the layer to the neural network model object `cnn_model`. \n",
    "\n",
    "    \n",
    "7. Create the pooling layer:\n",
    "    * Call `keras.layers.GlobalAveragePooling2D()` without arguments.\n",
    "    * Assign the result to the variable `pooling_layer`.\n",
    "    * Add `pooling_layer` to the neural network model object `cnn_model`. \n",
    "  \n",
    "  \n",
    "8. Create the output layer:\n",
    "    * Call `keras.layers.Dense()`. We will have one node per class. We have ten classes (digits from 0-9). Therefore, when creating the output later, specify 10 units. Do not specify an activation function.\n",
    "    * Assign the result to the variable `output_layer`.\n",
    "    * Add `output_layer` to the neural network model object `cnn_model`. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-66f19c486cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Step 8: Output layer (10 classes, no activation yet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'o' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Step 1: Create the CNN model object\n",
    "cnn_model = keras.Sequential()\n",
    "\n",
    "# Step 2: Input layer (assuming MNIST images: 28x28 pixels, grayscale)\n",
    "input_layer = layers.InputLayer(input_shape=(28, 28, 1))\n",
    "cnn_model.add(input_layer)\n",
    "\n",
    "# Step 3: First convolutional layer\n",
    "conv_1 = layers.Conv2D(filters=16, kernel_size=3)\n",
    "batchNorm_1 = layers.BatchNormalization()\n",
    "ReLU_1 = layers.ReLU()\n",
    "\n",
    "cnn_model.add(conv_1)\n",
    "cnn_model.add(batchNorm_1)\n",
    "cnn_model.add(ReLU_1)\n",
    "\n",
    "# Step 4: Second convolutional layer\n",
    "conv_2 = layers.Conv2D(filters=32, kernel_size=3)\n",
    "batchNorm_2 = layers.BatchNormalization()\n",
    "ReLU_2 = layers.ReLU()\n",
    "\n",
    "cnn_model.add(conv_2)\n",
    "cnn_model.add(batchNorm_2)\n",
    "cnn_model.add(ReLU_2)\n",
    "\n",
    "# Step 5: Third convolutional layer\n",
    "conv_3 = layers.Conv2D(filters=64, kernel_size=3)\n",
    "batchNorm_3 = layers.BatchNormalization()\n",
    "ReLU_3 = layers.ReLU()\n",
    "\n",
    "cnn_model.add(conv_3)\n",
    "cnn_model.add(batchNorm_3)\n",
    "cnn_model.add(ReLU_3)\n",
    "\n",
    "# Step 6: Fourth convolutional layer\n",
    "conv_4 = layers.Conv2D(filters=128, kernel_size=3)\n",
    "batchNorm_4 = layers.BatchNormalization()\n",
    "ReLU_4 = layers.ReLU()\n",
    "\n",
    "cnn_model.add(conv_4)\n",
    "cnn_model.add(batchNorm_4)\n",
    "cnn_model.add(ReLU_4)\n",
    "\n",
    "# Step 7: Global Average Pooling layer\n",
    "pooling_layer = layers.GlobalAveragePooling2D()\n",
    "cnn_model.add(pooling_layer)\n",
    "\n",
    "# Step 8: Output layer (10 classes, no activation yet)\n",
    "o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Define the Optimization Function\n",
    "\n",
    "<b>Task:</b> In the code cell below, create a stochastic gradient descent optimizer using  `keras.optimizers.SGD()`. Specify a learning rate of 0.1 using the `learning_rate` parameter. Assign the result to the variable`sgd_optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Step 2: Define the optimizer\n",
    "sgd_optimizer = SGD(learning_rate=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Define the loss function\n",
    "\n",
    "<b>Task:</b> In the code cell below, create a sparse categorical cross entropy loss function using `keras.losses.SparseCategoricalCrossentropy()`. This is an extension of the categorical cross entropy loss function. It is used when there are two or more label classes and the labels are integers. For more information, consult the online [SparseCategoricalCrossentropy documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy). Use the parameter `from_logits=True`. Assign the result to the variable  `loss_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Step 3: Define the loss function\n",
    "loss_fn = SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Compile the model\n",
    "\n",
    "<b>Task:</b> In the code cell below, package the network architecture with the optimizer and the loss function using the `cnn_model.compile()` method. Specify the optimizer, loss function and the accuracy evaluation metric as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile the CNN model\n",
    "cnn_model.compile(optimizer=sgd_optimizer,\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. Fit the Model to the Training Data\n",
    "\n",
    "We can now fit the CNN model to the training data. Since there are 60,000 training examples and nearly 100,000 parameters to fit, this may take a while to run. Therefore, we will only choose one epoch in this assignment.\n",
    "\n",
    "<b>Task:</b> In the code cell below, fit the CNN model to the training data using the `fit()` method. Call `cnn_model.fit()` with the following arguments:\n",
    "1. The training data sets.\n",
    "2. The number of epochs.\n",
    "\n",
    "Save the results to the variable `history`. \n",
    "\n",
    "<b>Note</b>: This may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training data if needed (e.g., if originally (60000, 28, 28))\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. Evaluate the Model's Performance\n",
    "\n",
    "Let's now evaluate our CNN model's performance on our test data and see how it did.\n",
    "\n",
    "\n",
    "<b>Task:</b> In the code cell below, call the `cnn_model.evaluate()` method with the test data sets as arguments. The `evaluate()` method returns a list containing two values. The first value is the loss and the second value is the accuracy score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 20ms/step - loss: 4.8520 - accuracy: 0.0000e+00\n",
      "\n",
      "Test Loss: 4.8520\n",
      "Test Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the CNN model on the test data\n",
    "test_loss, test_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll make some predictions on the test set and see for ourselves how accurate these predictions are.\n",
    "\n",
    "<b>Task:</b> In the code cell below, call the `plot_imgs()` functions with the first 25 images in `X_test` as the first argument, and the first 25 labels in `predictions` as the second argument. \n",
    "\n",
    "The result should be a display of the first 25 images in the test set `X_test`, and below each image, a display of the predicted digit. How well did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Get model predictions on the test set\n",
    "logits = cnn_model.predict(X_test)  # Raw outputs\n",
    "predictions = np.argmax(logits, axis=1)  # Convert logits to predicted labels\n",
    "\n",
    "# Step 2: Define a function to plot images and predictions\n",
    "def plot_imgs(images, labels, num_rows=5, num_cols=5):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num_rows * num_cols):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.xlabel(f\"Pred: {labels[i]}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Step 3: Plot the first 25 test images with predictions\n",
    "plot_imgs(X_test[:25], predictions[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
